{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Detectron2_Faster-R-CNN_VisDrone.ipynb adlı not defterinin kopyası",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "GeWnxsTpWXaJ"
      },
      "source": [
        "# install dependencies: \r\n",
        "!pip install pyyaml==5.1\r\n",
        "import torch, torchvision\r\n",
        "print(torch.__version__, torch.cuda.is_available())\r\n",
        "!gcc --version\r\n",
        "# opencv is pre-installed on colab"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yfhw0HOfWfRk"
      },
      "source": [
        "# install detectron2: (Colab has CUDA 10.1 + torch 1.7)\r\n",
        "# See https://detectron2.readthedocs.io/tutorials/install.html for instructions\r\n",
        "import torch\r\n",
        "assert torch.__version__.startswith(\"1.7\")\r\n",
        "!pip install detectron2 -f https://dl.fbaipublicfiles.com/detectron2/wheels/cu101/torch1.7/index.html\r\n",
        "exit(0)  # After installation, you need to \"restart runtime\" in Colab. This line can also restart runtime"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AoFB33PvWhXD",
        "outputId": "3b4a3c1b-952f-47da-d9e5-6ffa96a8211b"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount(\"/content/drive\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oNA3RZfcWhUO",
        "outputId": "fff9a46c-8e55-43e1-a36f-eb32eee981af"
      },
      "source": [
        "# Some basic setup:\r\n",
        "# Setup detectron2 logger\r\n",
        "import detectron2\r\n",
        "from detectron2.utils.logger import setup_logger\r\n",
        "setup_logger()\r\n",
        "\r\n",
        "# import some common libraries\r\n",
        "import random\r\n",
        "import numpy as np\r\n",
        "import logging\r\n",
        "import os, json, cv2, random\r\n",
        "from google.colab.patches import cv2_imshow\r\n",
        "from pathlib import Path\r\n",
        "from PIL import Image as PILImage\r\n",
        "import IPython\r\n",
        "from math import trunc\r\n",
        "import base64\r\n",
        "from io import BytesIO\r\n",
        "\r\n",
        "# import some common detectron2 utilities\r\n",
        "from detectron2 import model_zoo\r\n",
        "from detectron2.engine import DefaultPredictor\r\n",
        "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\r\n",
        "from detectron2.data import build_detection_test_loader\r\n",
        "from detectron2.config import get_cfg\r\n",
        "from detectron2.utils.visualizer import Visualizer\r\n",
        "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\r\n",
        "from detectron2.data import MetadataCatalog, DatasetCatalog\r\n",
        "from detectron2.structures import BoxMode\r\n",
        "from google.colab.patches import cv2_imshow\r\n",
        "from detectron2.utils.visualizer import ColorMode\r\n",
        "from detectron2.engine import DefaultTrainer\r\n",
        "from detectron2.config import get_cfg"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "** fvcore version of PathManager will be deprecated soon. **\n",
            "** Please migrate to the version in iopath repo. **\n",
            "https://github.com/facebookresearch/iopath \n",
            "\n",
            "** fvcore version of PathManager will be deprecated soon. **\n",
            "** Please migrate to the version in iopath repo. **\n",
            "https://github.com/facebookresearch/iopath \n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "m6YzhNbNWhRl"
      },
      "source": [
        "!unzip /content/drive/MyDrive/VisDrone2019-DET-train.zip -d /content/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p-OLiAMGs2N6"
      },
      "source": [
        "!unzip /content/drive/MyDrive/VisDrone2019-DET-val.zip -d /content/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HZGfoUuwWhPJ"
      },
      "source": [
        "#/content/VisDrone2019-DET-train/annotations\r\n",
        "def get_visdrone_dicts(img_path = \"/content/VisDrone2019-DET-train/images\", annot_path = \"/content/VisDrone2019-DET-train/annotations\" ):\r\n",
        "  dataset_dicts = []\r\n",
        "  for path, subdirs, files in os.walk(img_path):\r\n",
        "   for filename in files:\r\n",
        "     record = {}\r\n",
        "     \r\n",
        "     \r\n",
        "     img_p = os.path.join(path, filename)\r\n",
        "     anot_p = os.path.join(annot_path, filename[:-4] + '.txt')\r\n",
        "\r\n",
        "     h, w = cv2.imread(img_p).shape[:2]\r\n",
        "\r\n",
        "     record[\"file_name\"] = img_p\r\n",
        "     record[\"image_id\"] = filename\r\n",
        "     record[\"height\"] = h\r\n",
        "     record[\"width\"] = w\r\n",
        "\r\n",
        "     objs = []\r\n",
        "\r\n",
        "     with open(anot_p) as fp:\r\n",
        "       line = fp.readline()\r\n",
        "       while line:\r\n",
        "         line = line.replace(\"\\n\",\"\") \r\n",
        "         vals = line.split (\",\")\r\n",
        "         id = int(vals[5])\r\n",
        "         \r\n",
        "         if id==0 or id == 11:\r\n",
        "           id=0\r\n",
        "         elif id==1 or id==2:\r\n",
        "           id=1\r\n",
        "         else:\r\n",
        "           id=2    \r\n",
        "        \r\n",
        "         b_left, b_top, b_width, b_height = list(map(float,vals[:4]))\r\n",
        "         b_right, b_bottom = b_left + b_width, b_top - b_height\r\n",
        "         \r\n",
        "         obj = {\r\n",
        "            \"bbox\": [b_left, b_top, b_width, b_height],\r\n",
        "            \"bbox_mode\": BoxMode.XYWH_ABS,\r\n",
        "            \"segmentation\": [],\r\n",
        "            \"category_id\": id,\r\n",
        "         }\r\n",
        "         objs.append(obj)\r\n",
        "         line = fp.readline()\r\n",
        "     record[\"annotations\"] = objs\r\n",
        "     dataset_dicts.append(record)\r\n",
        "  \r\n",
        "  return dataset_dicts"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3QcU3NczrKkC"
      },
      "source": [
        "DatasetCatalog.register(\"train_set\",  lambda d=_: get_visdrone_dicts(\"/content/VisDrone2019-DET-train/images\", \"/content/VisDrone2019-DET-train/annotations\"))\r\n",
        "MetadataCatalog.get(\"train_set\").set(thing_classes =[\"Others\", \"Person\", \"Vehicle\"])\r\n",
        "MetadataCatalog.get(\"train_set\").thing_colors = [(0,255,0), (255,0,0), (0,0,255)]\r\n",
        "\r\n",
        "DatasetCatalog.register(\"val_set\",  lambda d=_: get_visdrone_dicts(\"/content/VisDrone2019-DET-val/images\", \"/content/VisDrone2019-DET-val/annotations\"))\r\n",
        "MetadataCatalog.get(\"val_set\").set(thing_classes =[\"Others\", \"Person\", \"Vehicle\"])\r\n",
        "MetadataCatalog.get(\"val_set\").thing_colors = [(0,255,0), (255,0,0), (0,0,255)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6BelW79WWhJm"
      },
      "source": [
        "train_metadata = MetadataCatalog.get(\"train_set\")\r\n",
        "val_metadata = MetadataCatalog.get(\"val_set\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sM95yiUiuJNc",
        "outputId": "cc3da1d8-a17f-450a-fc72-e5538a9d361d"
      },
      "source": [
        "val_metadata"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Metadata(name='val_set', thing_classes=['Others', 'Person', 'Vehicle'], thing_colors=[(0, 255, 0), (255, 0, 0), (0, 0, 255)])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gjumE-g2WvzR"
      },
      "source": [
        "train_set_dicts = get_visdrone_dicts(\"/content/VisDrone2019-DET-train/images\", \"/content/VisDrone2019-DET-train/annotations\")\r\n",
        "val_set_dicts = get_visdrone_dicts(\"/content/VisDrone2019-DET-val/images\", \"/content/VisDrone2019-DET-val/annotations\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qxKgZw6_lHCL"
      },
      "source": [
        "from detectron2.engine.hooks import HookBase\r\n",
        "from detectron2.evaluation import inference_context\r\n",
        "from detectron2.utils.logger import log_every_n_seconds\r\n",
        "from detectron2.data import DatasetMapper, build_detection_test_loader\r\n",
        "import detectron2.utils.comm as comm\r\n",
        "import torch\r\n",
        "import time\r\n",
        "import datetime\r\n",
        "\r\n",
        "class LossEvalHook(HookBase):\r\n",
        "    def __init__(self, eval_period, model, data_loader):\r\n",
        "        self._model = model\r\n",
        "        self._period = eval_period\r\n",
        "        self._data_loader = data_loader\r\n",
        "    \r\n",
        "    def _do_loss_eval(self):\r\n",
        "        # Copying inference_on_dataset from evaluator.py\r\n",
        "        total = len(self._data_loader)\r\n",
        "        num_warmup = min(5, total - 1)\r\n",
        "            \r\n",
        "        start_time = time.perf_counter()\r\n",
        "        total_compute_time = 0\r\n",
        "        losses = []\r\n",
        "        for idx, inputs in enumerate(self._data_loader):            \r\n",
        "            if idx == num_warmup:\r\n",
        "                start_time = time.perf_counter()\r\n",
        "                total_compute_time = 0\r\n",
        "            start_compute_time = time.perf_counter()\r\n",
        "            if torch.cuda.is_available():\r\n",
        "                torch.cuda.synchronize()\r\n",
        "            total_compute_time += time.perf_counter() - start_compute_time\r\n",
        "            iters_after_start = idx + 1 - num_warmup * int(idx >= num_warmup)\r\n",
        "            seconds_per_img = total_compute_time / iters_after_start\r\n",
        "            if idx >= num_warmup * 2 or seconds_per_img > 5:\r\n",
        "                total_seconds_per_img = (time.perf_counter() - start_time) / iters_after_start\r\n",
        "                eta = datetime.timedelta(seconds=int(total_seconds_per_img * (total - idx - 1)))\r\n",
        "                log_every_n_seconds(\r\n",
        "                    logging.INFO,\r\n",
        "                    \"Loss on Validation  done {}/{}. {:.4f} s / img. ETA={}\".format(\r\n",
        "                        idx + 1, total, seconds_per_img, str(eta)\r\n",
        "                    ),\r\n",
        "                    n=5,\r\n",
        "                )\r\n",
        "            loss_batch = self._get_loss(inputs)\r\n",
        "            losses.append(loss_batch)\r\n",
        "        mean_loss = np.mean(losses)\r\n",
        "        self.trainer.storage.put_scalar('validation_loss', mean_loss)\r\n",
        "        comm.synchronize()\r\n",
        "\r\n",
        "        return losses\r\n",
        "            \r\n",
        "    def _get_loss(self, data):\r\n",
        "        # How loss is calculated on train_loop \r\n",
        "        metrics_dict = self._model(data)\r\n",
        "        metrics_dict = {\r\n",
        "            k: v.detach().cpu().item() if isinstance(v, torch.Tensor) else float(v)\r\n",
        "            for k, v in metrics_dict.items()\r\n",
        "        }\r\n",
        "        total_losses_reduced = sum(loss for loss in metrics_dict.values())\r\n",
        "        return total_losses_reduced\r\n",
        "        \r\n",
        "        \r\n",
        "    def after_step(self):\r\n",
        "        next_iter = self.trainer.iter + 1\r\n",
        "        is_final = next_iter == self.trainer.max_iter\r\n",
        "        if is_final or (self._period > 0 and next_iter % self._period == 0):\r\n",
        "            self._do_loss_eval()\r\n",
        "        self.trainer.storage.put_scalars(timetest=12)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aq8T0us7lJtB"
      },
      "source": [
        "class MyTrainer(DefaultTrainer):\r\n",
        "    @classmethod\r\n",
        "    def build_evaluator(cls, cfg, dataset_name, output_folder=None):\r\n",
        "        if output_folder is None:\r\n",
        "            output_folder = os.path.join(cfg.OUTPUT_DIR, \"inference\")\r\n",
        "        return COCOEvaluator(dataset_name, cfg, True, output_folder)\r\n",
        "                     \r\n",
        "    def build_hooks(self):\r\n",
        "        hooks = super().build_hooks()\r\n",
        "        hooks.insert(-1,LossEvalHook(\r\n",
        "            cfg.TEST.EVAL_PERIOD,\r\n",
        "            self.model,\r\n",
        "            build_detection_test_loader(\r\n",
        "                self.cfg,\r\n",
        "                self.cfg.DATASETS.TEST[0],\r\n",
        "                DatasetMapper(self.cfg,True)\r\n",
        "            )\r\n",
        "        ))\r\n",
        "        return hooks\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LsMoAsPF0Mfp"
      },
      "source": [
        "Train the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "tVYuRCK9YOU8"
      },
      "source": [
        "cfg = get_cfg()\r\n",
        "cfg.merge_from_file(\r\n",
        "    model_zoo.get_config_file(\"COCO-Detection/faster_rcnn_X_101_32x8d_FPN_3x.yaml\")\r\n",
        ")\r\n",
        "cfg.DATASETS.TRAIN = (\"train_set\",)\r\n",
        "cfg.DATASETS.TEST = (\"val_set\",)\r\n",
        "cfg.DATALOADER.NUM_WORKERS = 2\r\n",
        "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-Detection/faster_rcnn_X_101_32x8d_FPN_3x.yaml\")\r\n",
        "cfg.SOLVER.IMS_PER_BATCH = 2\r\n",
        "cfg.SOLVER.BASE_LR = 0.0003\r\n",
        "cfg.SOLVER.MAX_ITER = (6000)\r\n",
        "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = (1024)\r\n",
        "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 3\r\n",
        "\r\n",
        "print(cfg)\r\n",
        "\r\n",
        "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\r\n",
        "trainer = MyTrainer(cfg)\r\n",
        "trainer.resume_or_load(resume=False)\r\n",
        "trainer.train()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UmgHHzQAW5G7"
      },
      "source": [
        "# Look at training curves in tensorboard:\r\n",
        "%load_ext tensorboard\r\n",
        "%tensorboard --logdir output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xqyqbcqrlKLB"
      },
      "source": [
        "import json\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "\r\n",
        "experiment_folder = '/content/output'\r\n",
        "\r\n",
        "def load_json_arr(json_path):\r\n",
        "    lines = []\r\n",
        "    with open(json_path, 'r') as f:\r\n",
        "        for line in f:\r\n",
        "            lines.append(json.loads(line))\r\n",
        "    return lines\r\n",
        "\r\n",
        "experiment_metrics = load_json_arr(experiment_folder + '/metrics.json')\r\n",
        "\r\n",
        "plt.plot(\r\n",
        "    [x['iteration'] for x in experiment_metrics], \r\n",
        "    [x['total_loss'] for x in experiment_metrics])\r\n",
        "plt.plot(\r\n",
        "    [x['iteration'] for x in experiment_metrics if 'validation_loss' in x], \r\n",
        "    [x['validation_loss'] for x in experiment_metrics if 'validation_loss' in x])\r\n",
        "plt.legend(['total_loss', 'validation_loss'], loc='upper left')\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CwB4ywKI0IUN"
      },
      "source": [
        "Test the model on teset set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YvHXSmlhW5Ea"
      },
      "source": [
        "!unzip /content/drive/MyDrive/VisDrone2019-DET-test-dev.zip -d /content/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UJPeTOzbW5Bt"
      },
      "source": [
        "DatasetCatalog.register(\"test_set\",  lambda d=_: get_visdrone_dicts(\"/content/images\", \"/content/annotations\"))\r\n",
        "MetadataCatalog.get(\"test_set\").set(thing_classes =[\"Others\", \"Person\", \"Vehicle\"])\r\n",
        "MetadataCatalog.get(\"test_set\").thing_colors = [(0,255,0), (255,0,0), (0,0,255)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-icftCMLXEfY"
      },
      "source": [
        "balloon_metadata = MetadataCatalog.get(\"test_set\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lu8KWE0dXEXS"
      },
      "source": [
        "dataset_dicts = get_visdrone_dicts(\"/content/images\", \"/content/annotations\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XdH2o-qcXEOI"
      },
      "source": [
        "# Inference should use the config with parameters that are used in training\r\n",
        "# cfg now already contains everything we've set previously. We changed it a little bit for inference:\r\n",
        "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"/content/output/model_final.pth\")  # path to the model we just trained\r\n",
        "#cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.4   # set a custom testing threshold\r\n",
        "cfg.MODEL.RETINANET.SCORE_THRESH_TEST = 0.7\r\n",
        "cfg.DATASETS.TEST = ( )\r\n",
        "predictor = DefaultPredictor(cfg)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ogPCtt6gXRko"
      },
      "source": [
        "for d in random.sample(dataset_dicts, 10):    \r\n",
        "    im = cv2.imread(d[\"file_name\"])\r\n",
        "    outputs = predictor(im)\r\n",
        "    v = Visualizer(im[:, :, ::-1],\r\n",
        "                   metadata=balloon_metadata, \r\n",
        "                   scale=1.5, \r\n",
        "                   instance_mode=ColorMode.SEGMENTATION   # remove the colors of unsegmented pixels\r\n",
        "    )\r\n",
        "    v = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\r\n",
        "    cv2_imshow(v.get_image()[:, :, ::-1])\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EXJ7icr2XnWK"
      },
      "source": [
        "#import the COCO Evaluator to use the COCO Metrics\r\n",
        "\r\n",
        "#Call the COCO Evaluator function and pass the Validation Dataset\r\n",
        "evaluator = COCOEvaluator(\"test_set\", cfg, False, output_dir=\"/output2/\")\r\n",
        "val_loader = build_detection_test_loader(cfg, \"test_set\")\r\n",
        "\r\n",
        "#Use the created predicted model in the previous step\r\n",
        "inference_on_dataset(predictor.model, val_loader, evaluator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VBbh-grWYmf_"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}