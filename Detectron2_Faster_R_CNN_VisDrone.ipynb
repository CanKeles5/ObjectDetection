{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Detectron2_Faster-R-CNN_VisDrone.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOnV2Y7SdnlRSPOlUsH/WBN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CanKeles5/ObjectDetection/blob/main/Detectron2_Faster_R_CNN_VisDrone.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GeWnxsTpWXaJ"
      },
      "source": [
        "# install dependencies: \r\n",
        "!pip install pyyaml==5.1\r\n",
        "import torch, torchvision\r\n",
        "print(torch.__version__, torch.cuda.is_available())\r\n",
        "!gcc --version\r\n",
        "# opencv is pre-installed on colab"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yfhw0HOfWfRk"
      },
      "source": [
        "# install detectron2: (Colab has CUDA 10.1 + torch 1.7)\r\n",
        "# See https://detectron2.readthedocs.io/tutorials/install.html for instructions\r\n",
        "import torch\r\n",
        "assert torch.__version__.startswith(\"1.7\")\r\n",
        "!pip install detectron2 -f https://dl.fbaipublicfiles.com/detectron2/wheels/cu101/torch1.7/index.html\r\n",
        "exit(0)  # After installation, you need to \"restart runtime\" in Colab. This line can also restart runtime"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AoFB33PvWhXD"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount(\"/content/drive\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oNA3RZfcWhUO"
      },
      "source": [
        "# Some basic setup:\r\n",
        "# Setup detectron2 logger\r\n",
        "import detectron2\r\n",
        "from detectron2.utils.logger import setup_logger\r\n",
        "setup_logger()\r\n",
        "\r\n",
        "# import some common libraries\r\n",
        "import random\r\n",
        "import numpy as np\r\n",
        "import os, json, cv2, random\r\n",
        "from google.colab.patches import cv2_imshow\r\n",
        "\r\n",
        "# import some common detectron2 utilities\r\n",
        "from detectron2 import model_zoo\r\n",
        "from detectron2.engine import DefaultPredictor\r\n",
        "from detectron2.config import get_cfg\r\n",
        "from detectron2.utils.visualizer import Visualizer\r\n",
        "from detectron2.data import MetadataCatalog, DatasetCatalog\r\n",
        "from detectron2.structures import BoxMode\r\n",
        "from google.colab.patches import cv2_imshow\r\n",
        "from detectron2.utils.visualizer import ColorMode"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m6YzhNbNWhRl"
      },
      "source": [
        "!unzip /content/drive/MyDrive/VisDrone2019-DET-train.zip -d /content/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HZGfoUuwWhPJ"
      },
      "source": [
        "#/content/VisDrone2019-DET-train/annotations\r\n",
        "def get_visdrone_dicts(img_path = \"/content/VisDrone2019-DET-train/images\", annot_path = \"/content/VisDrone2019-DET-train/annotations\" ):\r\n",
        "  dataset_dicts = []\r\n",
        "  for path, subdirs, files in os.walk(img_path):\r\n",
        "   for filename in files:\r\n",
        "     record = {}\r\n",
        "     \r\n",
        "     \r\n",
        "     img_p = os.path.join(path, filename)\r\n",
        "     anot_p = os.path.join(annot_path, filename[:-4] + '.txt')\r\n",
        "\r\n",
        "     h, w = cv2.imread(img_p).shape[:2]\r\n",
        "\r\n",
        "     record[\"file_name\"] = img_p\r\n",
        "     record[\"image_id\"] = filename\r\n",
        "     record[\"height\"] = h\r\n",
        "     record[\"width\"] = w\r\n",
        "\r\n",
        "     objs = []\r\n",
        "\r\n",
        "     with open(anot_p) as fp:\r\n",
        "       line = fp.readline()\r\n",
        "       while line:\r\n",
        "         line = line.replace(\"\\n\",\"\") \r\n",
        "         vals = line.split (\",\")\r\n",
        "         id = int(vals[5])\r\n",
        "\r\n",
        "         '''if id == 0 or id == 11:\r\n",
        "           line = fp.readline()\r\n",
        "           continue\r\n",
        "        '''\r\n",
        "        \r\n",
        "         b_left, b_top, b_width, b_height = list(map(float,vals[:4]))\r\n",
        "         b_right, b_bottom = b_left + b_width, b_top - b_height\r\n",
        "         \r\n",
        "         obj = {\r\n",
        "            \"bbox\": [b_left, b_top, b_width, b_height],\r\n",
        "            \"bbox_mode\": BoxMode.XYWH_ABS,\r\n",
        "            \"segmentation\": [],\r\n",
        "            \"category_id\": id,\r\n",
        "         }\r\n",
        "         objs.append(obj)\r\n",
        "         line = fp.readline()\r\n",
        "     record[\"annotations\"] = objs\r\n",
        "     dataset_dicts.append(record)\r\n",
        "         #print(dataset_dicts)\r\n",
        "  return dataset_dicts\r\n",
        "     #print(img_p)\r\n",
        "     #cv2_imshow(image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a4_vXdUoWhMQ"
      },
      "source": [
        "DatasetCatalog.register(\"datset9\",  lambda d=_: get_visdrone_dicts(\"/content/VisDrone2019-DET-train/images\", \"/content/VisDrone2019-DET-train/annotations\"))\r\n",
        "MetadataCatalog.get(\"datset9\").set(thing_classes =[\"Ignored\", \"Pedestrian\", \"People\", \"Bicycle\", \"Car\", \"Van\", \"Truck\", \"Tricycle\", \"awning-tricycle\", \"Bus\", \"Motor\", \"Others\"])\r\n",
        "MetadataCatalog.get(\"datset9\").thing_colors = [(0,255,0), (255,0,0), (255,0,0), (0,0,255), (0,0,255), (0,0,255),(0,0,255),(0,0,255),(0,0,255),(0,0,255),(0,0,255),(0,255,0)]\r\n",
        "#MetadataCatalog.get(\"datset6\").thing_colors = [(102,255,102), (102,255,255), (102,102,255), (0,0,255), (255,0,0), (0,255,0),(140,50,160),(50,200,100),(160,70,200),(100,200,20),(100,200,20),(200,100,100)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6BelW79WWhJm"
      },
      "source": [
        "balloon_metadata = MetadataCatalog.get(\"datset9\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gjumE-g2WvzR"
      },
      "source": [
        "dataset_dicts = get_visdrone_dicts(\"/content/VisDrone2019-DET-train/images\", \"/content/VisDrone2019-DET-train/annotations\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ffHk1SfkWvxK"
      },
      "source": [
        "balloon_metadata"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fk5hspLgWvue"
      },
      "source": [
        "from detectron2.utils.visualizer import ColorMode\r\n",
        "for d in dataset_dicts[:5]:\r\n",
        "    img = cv2.imread(d[\"file_name\"])\r\n",
        "    visualizer = Visualizer(img[:, :, ::-1], metadata=balloon_metadata, scale=1.5, instance_mode=ColorMode.SEGMENTATION)\r\n",
        "    out = visualizer.draw_dataset_dict(d)\r\n",
        "    cv2_imshow(out.get_image()[:, :, ::-1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-z7xDxC-Wvr9"
      },
      "source": [
        "import json\r\n",
        "from pathlib import Path\r\n",
        "from PIL import Image as PILImage\r\n",
        "import IPython\r\n",
        "import numpy as np\r\n",
        "from math import trunc\r\n",
        "import base64\r\n",
        "from io import BytesIO"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2GlWarSlW5L0"
      },
      "source": [
        "annot_path = \"/content/drive/MyDrive/visdronecoco.json\"\r\n",
        "img_path = \"/content/VisDrone2019-DET-train/images\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1OiVPR5iW5Jb"
      },
      "source": [
        "from detectron2.engine import DefaultTrainer\r\n",
        "\r\n",
        "cfg = get_cfg()\r\n",
        "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-Detection/retinanet_R_101_FPN_3x.yaml\"))\r\n",
        "cfg.DATASETS.TRAIN = (\"datset9\",)\r\n",
        "cfg.DATASETS.TEST = ()\r\n",
        "cfg.DATALOADER.NUM_WORKERS = 2\r\n",
        "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-Detection/retinanet_R_101_FPN_3x.yaml\")  # Let training initialize from model zoo\r\n",
        "cfg.SOLVER.IMS_PER_BATCH = 4\r\n",
        "cfg.SOLVER.BASE_LR = 0.0002  # pick a good LR\r\n",
        "cfg.SOLVER.MAX_ITER = 4000    # 300 iterations seems good enough for this toy dataset; you will need to train longer for a practical dataset\r\n",
        "cfg.SOLVER.STEPS = []        # do not decay learning rate\r\n",
        "#cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 512   # faster, and good enough for this toy dataset (default: 512)\r\n",
        "cfg.MODEL.RETINANET.NUM_CLASSES = 12  # only has one class (ballon). (see https://detectron2.readthedocs.io/tutorials/datasets.html#update-the-config-for-new-datasets)\r\n",
        "# NOTE: this config means the number of classes, but a few popular unofficial tutorials incorrect uses num_classes+1 here.\r\n",
        "\r\n",
        "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\r\n",
        "trainer = DefaultTrainer(cfg) \r\n",
        "trainer.resume_or_load(resume=False)\r\n",
        "trainer.train()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UmgHHzQAW5G7"
      },
      "source": [
        "# Look at training curves in tensorboard:\r\n",
        "%load_ext tensorboard\r\n",
        "%tensorboard --logdir output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YvHXSmlhW5Ea"
      },
      "source": [
        "!unzip /content/drive/MyDrive/VisDrone2019-DET-test-dev.zip -d /content/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UJPeTOzbW5Bt"
      },
      "source": [
        "DatasetCatalog.register(\"datset10\",  lambda d= _: get_visdrone_dicts(\"/content/images\", \"/content/annotations\"))\r\n",
        "MetadataCatalog.get(\"datset10\").set(thing_classes =[\"Ignored\", \"Pedestrian\", \"People\", \"Bicycle\", \"Car\", \"Van\", \"Truck\", \"Tricycle\", \"awning-tricycle\", \"Bus\", \"Motor\", \"Others\"])\r\n",
        "MetadataCatalog.get(\"datset10\").thing_colors = [(0,255,0), (255,0,0), (255,0,0), (0,0,255), (0,0,255), (0,0,255),(0,0,255),(0,0,255),(0,0,255),(0,0,255),(0,0,255),(0,255,0)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-icftCMLXEfY"
      },
      "source": [
        "balloon_metadata = MetadataCatalog.get(\"datset10\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lu8KWE0dXEXS"
      },
      "source": [
        "dataset_dicts = get_visdrone_dicts(\"/content/images\", \"/content/annotations\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e4H1giG-XEUS"
      },
      "source": [
        "print(cfg.OUTPUT_DIR)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XdH2o-qcXEOI"
      },
      "source": [
        "# Inference should use the config with parameters that are used in training\r\n",
        "# cfg now already contains everything we've set previously. We changed it a little bit for inference:\r\n",
        "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"/content/output/model_final.pth\")  # path to the model we just trained\r\n",
        "#cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.4   # set a custom testing threshold\r\n",
        "cfg.MODEL.RETINANET.SCORE_THRESH_TEST = 0.45\r\n",
        "cfg.DATASETS.TEST = ( )\r\n",
        "predictor = DefaultPredictor(cfg)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ogPCtt6gXRko"
      },
      "source": [
        "for d in random.sample(dataset_dicts, 10):    \r\n",
        "    im = cv2.imread(d[\"file_name\"])\r\n",
        "    outputs = predictor(im)\r\n",
        "    v = Visualizer(im[:, :, ::-1],\r\n",
        "                   metadata=balloon_metadata, \r\n",
        "                   scale=1.5, \r\n",
        "                   instance_mode=ColorMode.SEGMENTATION   # remove the colors of unsegmented pixels\r\n",
        "    )\r\n",
        "    v = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\r\n",
        "    cv2_imshow(v.get_image()[:, :, ::-1])\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EXJ7icr2XnWK"
      },
      "source": [
        "#import the COCO Evaluator to use the COCO Metrics\r\n",
        "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\r\n",
        "from detectron2.data import build_detection_test_loader\r\n",
        "\r\n",
        "#Call the COCO Evaluator function and pass the Validation Dataset\r\n",
        "evaluator = COCOEvaluator(\"datset9\", cfg, False, output_dir=\"/output2/\")\r\n",
        "val_loader = build_detection_test_loader(cfg, \"datset9\")\r\n",
        "\r\n",
        "#Use the created predicted model in the previous step\r\n",
        "inference_on_dataset(predictor.model, val_loader, evaluator)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}