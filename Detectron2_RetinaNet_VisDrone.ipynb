{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Detectron2-RetinaNet-VisDrone.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CanKeles5/ObjectDetection/blob/main/Detectron2_RetinaNet_VisDrone.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tL2iCtBwe2Sq"
      },
      "source": [
        "# install dependencies: \r\n",
        "!pip install pyyaml==5.1\r\n",
        "import torch, torchvision\r\n",
        "print(torch.__version__, torch.cuda.is_available())\r\n",
        "!gcc --version\r\n",
        "# opencv is pre-installed on colab"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bwgdJqSje5fA"
      },
      "source": [
        "# install detectron2: (Colab has CUDA 10.1 + torch 1.7)\r\n",
        "# See https://detectron2.readthedocs.io/tutorials/install.html for instructions\r\n",
        "import torch\r\n",
        "assert torch.__version__.startswith(\"1.7\")\r\n",
        "!pip install detectron2 -f https://dl.fbaipublicfiles.com/detectron2/wheels/cu101/torch1.7/index.html\r\n",
        "exit(0)  # After installation, you need to \"restart runtime\" in Colab. This line can also restart runtime"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WMbxAFygpwfQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1e4487b-4e47-4091-f8cf-be49c5f80546"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount(\"/content/drive\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WR3JLB7Qe--k"
      },
      "source": [
        "# Some basic setup:\r\n",
        "# Setup detectron2 logger\r\n",
        "import detectron2\r\n",
        "from detectron2.utils.logger import setup_logger\r\n",
        "setup_logger()\r\n",
        "\r\n",
        "# import some common libraries\r\n",
        "import numpy as np\r\n",
        "import os, json, cv2, random\r\n",
        "from google.colab.patches import cv2_imshow\r\n",
        "\r\n",
        "# import some common detectron2 utilities\r\n",
        "from detectron2 import model_zoo\r\n",
        "from detectron2.engine import DefaultPredictor\r\n",
        "from detectron2.config import get_cfg\r\n",
        "from detectron2.utils.visualizer import Visualizer\r\n",
        "from detectron2.data import MetadataCatalog, DatasetCatalog"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CXdTQLLpeDEB"
      },
      "source": [
        "!unzip /content/drive/MyDrive/VisDrone2019-DET-train.zip -d /content/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SlW1sa8amIA2"
      },
      "source": [
        "from detectron2.structures import BoxMode"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ERbZOUTrmLvo"
      },
      "source": [
        "from google.colab.patches import cv2_imshow\r\n",
        "#/content/VisDrone2019-DET-train/annotations\r\n",
        "def get_visdrone_dicts(img_path = \"/content/VisDrone2019-DET-train/images\", annot_path = \"/content/VisDrone2019-DET-train/annotations\" ):\r\n",
        "  dataset_dicts = []\r\n",
        "  for path, subdirs, files in os.walk(img_path):\r\n",
        "   for filename in files:\r\n",
        "     record = {}\r\n",
        "     \r\n",
        "     \r\n",
        "     img_p = os.path.join(path, filename)\r\n",
        "     anot_p = os.path.join(annot_path, filename[:-4] + '.txt')\r\n",
        "\r\n",
        "     h, w = cv2.imread(img_p).shape[:2]\r\n",
        "\r\n",
        "     record[\"file_name\"] = img_p\r\n",
        "     record[\"image_id\"] = filename\r\n",
        "     record[\"height\"] = h\r\n",
        "     record[\"width\"] = w\r\n",
        "\r\n",
        "     objs = []\r\n",
        "\r\n",
        "     with open(anot_p) as fp:\r\n",
        "       line = fp.readline()\r\n",
        "       while line:\r\n",
        "         line = line.replace(\"\\n\",\"\") \r\n",
        "         vals = line.split (\",\")\r\n",
        "         id = int(vals[5])\r\n",
        "\r\n",
        "         '''if id == 0 or id == 11:\r\n",
        "           line = fp.readline()\r\n",
        "           continue\r\n",
        "        '''\r\n",
        "        \r\n",
        "         b_left, b_top, b_width, b_height = list(map(float,vals[:4]))\r\n",
        "         b_right, b_bottom = b_left + b_width, b_top - b_height\r\n",
        "         \r\n",
        "         obj = {\r\n",
        "            \"bbox\": [b_left, b_top, b_width, b_height],\r\n",
        "            \"bbox_mode\": BoxMode.XYWH_ABS,\r\n",
        "            \"segmentation\": [],\r\n",
        "            \"category_id\": id,\r\n",
        "         }\r\n",
        "         objs.append(obj)\r\n",
        "         line = fp.readline()\r\n",
        "     record[\"annotations\"] = objs\r\n",
        "     dataset_dicts.append(record)\r\n",
        "         #print(dataset_dicts)\r\n",
        "  return dataset_dicts\r\n",
        "     #print(img_p)\r\n",
        "     #cv2_imshow(image)\r\n",
        "     "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A9NWiTA6_Sxh"
      },
      "source": [
        "ignored regions(0), pedestrian(1), \r\n",
        "                     people(2), bicycle(3), car(4), van(5), truck(6), tricycle(7), awning-tricycle(8), bus(9), motor(10), \r\n",
        "                     others(11)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2m0Wz5Y09Qcv"
      },
      "source": [
        "DatasetCatalog.register(\"datset9\",  lambda d=_: get_visdrone_dicts(\"/content/VisDrone2019-DET-train/images\", \"/content/VisDrone2019-DET-train/annotations\"))\r\n",
        "MetadataCatalog.get(\"datset9\").set(thing_classes =[\"Ignored\", \"Pedestrian\", \"People\", \"Bicycle\", \"Car\", \"Van\", \"Truck\", \"Tricycle\", \"awning-tricycle\", \"Bus\", \"Motor\", \"Others\"])\r\n",
        "MetadataCatalog.get(\"datset9\").thing_colors = [(0,255,0), (255,0,0), (255,0,0), (0,0,255), (0,0,255), (0,0,255),(0,0,255),(0,0,255),(0,0,255),(0,0,255),(0,0,255),(0,255,0)]\r\n",
        "#MetadataCatalog.get(\"datset6\").thing_colors = [(102,255,102), (102,255,255), (102,102,255), (0,0,255), (255,0,0), (0,255,0),(140,50,160),(50,200,100),(160,70,200),(100,200,20),(100,200,20),(200,100,100)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oOzLSdFsC6FX"
      },
      "source": [
        "balloon_metadata = MetadataCatalog.get(\"datset9\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aXrlNIVw8z-x"
      },
      "source": [
        "dataset_dicts = get_visdrone_dicts(\"/content/VisDrone2019-DET-train/images\", \"/content/VisDrone2019-DET-train/annotations\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sOl9bgLhYa5u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d71d6d6-6d9e-4222-d378-ec606d0171d5"
      },
      "source": [
        "balloon_metadata"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Metadata(name='datset9', thing_classes=['Ignored', 'Pedestrian', 'People', 'Bicycle', 'Car', 'Van', 'Truck', 'Tricycle', 'awning-tricycle', 'Bus', 'Motor', 'Others'], thing_colors=[(0, 255, 0), (255, 0, 0), (255, 0, 0), (0, 0, 255), (0, 0, 255), (0, 0, 255), (0, 0, 255), (0, 0, 255), (0, 0, 255), (0, 0, 255), (0, 0, 255), (0, 255, 0)])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wpueh-Gf88yu"
      },
      "source": [
        "from detectron2.utils.visualizer import ColorMode\r\n",
        "for d in dataset_dicts[:5]:\r\n",
        "    img = cv2.imread(d[\"file_name\"])\r\n",
        "    visualizer = Visualizer(img[:, :, ::-1], metadata=balloon_metadata, scale=1.5, instance_mode=ColorMode.SEGMENTATION)\r\n",
        "    out = visualizer.draw_dataset_dict(d)\r\n",
        "    cv2_imshow(out.get_image()[:, :, ::-1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o2OJc_pTHk6q"
      },
      "source": [
        "import json\r\n",
        "from pathlib import Path\r\n",
        "from PIL import Image as PILImage\r\n",
        "import IPython\r\n",
        "import numpy as np\r\n",
        "from math import trunc\r\n",
        "import base64\r\n",
        "from io import BytesIO"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eghbDpRmj_r4"
      },
      "source": [
        "annot_path = \"/content/drive/MyDrive/visdronecoco.json\"\r\n",
        "img_path = \"/content/VisDrone2019-DET-train/images\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "47EhGgdejmCI"
      },
      "source": [
        "from detectron2.engine import DefaultTrainer\r\n",
        "\r\n",
        "cfg = get_cfg()\r\n",
        "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-Detection/retinanet_R_101_FPN_3x.yaml\"))\r\n",
        "cfg.DATASETS.TRAIN = (\"datset9\",)\r\n",
        "cfg.DATASETS.TEST = ()\r\n",
        "cfg.DATALOADER.NUM_WORKERS = 2\r\n",
        "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-Detection/retinanet_R_101_FPN_3x.yaml\")  # Let training initialize from model zoo\r\n",
        "cfg.SOLVER.IMS_PER_BATCH = 4\r\n",
        "cfg.SOLVER.BASE_LR = 0.0002  # pick a good LR\r\n",
        "cfg.SOLVER.MAX_ITER = 4000    # 300 iterations seems good enough for this toy dataset; you will need to train longer for a practical dataset\r\n",
        "cfg.SOLVER.STEPS = []        # do not decay learning rate\r\n",
        "#cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 512   # faster, and good enough for this toy dataset (default: 512)\r\n",
        "cfg.MODEL.RETINANET.NUM_CLASSES = 12  # only has one class (ballon). (see https://detectron2.readthedocs.io/tutorials/datasets.html#update-the-config-for-new-datasets)\r\n",
        "# NOTE: this config means the number of classes, but a few popular unofficial tutorials incorrect uses num_classes+1 here.\r\n",
        "\r\n",
        "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\r\n",
        "trainer = DefaultTrainer(cfg) \r\n",
        "trainer.resume_or_load(resume=False)\r\n",
        "trainer.train()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SgDOfFpnJkSD"
      },
      "source": [
        "# Look at training curves in tensorboard:\r\n",
        "%load_ext tensorboard\r\n",
        "%tensorboard --logdir output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nMwlCM7lQ2mX"
      },
      "source": [
        "#!unzip /content/drive/MyDrive/VisDrone2019-VID-test-dev.zip -d /content/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MwDRUmtgRVg_"
      },
      "source": [
        "!unzip /content/drive/MyDrive/VisDrone2019-DET-test-dev.zip -d /content/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AHMv2kdkU91q"
      },
      "source": [
        "DatasetCatalog.register(\"datset10\",  lambda d= _: get_visdrone_dicts(\"/content/images\", \"/content/annotations\"))\r\n",
        "MetadataCatalog.get(\"datset10\").set(thing_classes =[\"Ignored\", \"Pedestrian\", \"People\", \"Bicycle\", \"Car\", \"Van\", \"Truck\", \"Tricycle\", \"awning-tricycle\", \"Bus\", \"Motor\", \"Others\"])\r\n",
        "MetadataCatalog.get(\"datset10\").thing_colors = [(0,255,0), (255,0,0), (255,0,0), (0,0,255), (0,0,255), (0,0,255),(0,0,255),(0,0,255),(0,0,255),(0,0,255),(0,0,255),(0,255,0)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WfOPL0gcVRwu"
      },
      "source": [
        "balloon_metadata = MetadataCatalog.get(\"datset10\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "71a-8MZiVRoC"
      },
      "source": [
        "dataset_dicts = get_visdrone_dicts(\"/content/images\", \"/content/annotations\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yROl1lst1dYK",
        "outputId": "bc034222-dfc5-4c98-e7d1-5160fda196d6"
      },
      "source": [
        "print(cfg.OUTPUT_DIR)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "./output\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oRaAbW8jVovc"
      },
      "source": [
        "# Inference should use the config with parameters that are used in training\r\n",
        "# cfg now already contains everything we've set previously. We changed it a little bit for inference:\r\n",
        "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"/content/output/model_final.pth\")  # path to the model we just trained\r\n",
        "#cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.4   # set a custom testing threshold\r\n",
        "cfg.MODEL.RETINANET.SCORE_THRESH_TEST = 0.45\r\n",
        "cfg.DATASETS.TEST = ( )\r\n",
        "predictor = DefaultPredictor(cfg)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "QBaP5__cVpUg"
      },
      "source": [
        "import random\r\n",
        "from detectron2.utils.visualizer import ColorMode\r\n",
        "from detectron2.utils.visualizer import Visualizer\r\n",
        "\r\n",
        "for d in random.sample(dataset_dicts, 5):\r\n",
        "    img = cv2.imread(d[\"file_name\"])\r\n",
        "    visualizer = Visualizer(img[:, :, ::-1], metadata=balloon_metadata, scale=1.5,instance_mode=ColorMode.SEGMENTATION)\r\n",
        "    vis = visualizer.draw_dataset_dict(d)\r\n",
        "    cv2_imshow(vis.get_image()[:, :, ::-1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hR7tZHWrX5-i"
      },
      "source": [
        "from detectron2.utils.visualizer import ColorMode\r\n",
        "\r\n",
        "for d in random.sample(dataset_dicts, 5):    \r\n",
        "    im = cv2.imread(d[\"file_name\"])\r\n",
        "    outputs = predictor(im)\r\n",
        "    v = Visualizer(im[:, :, ::-1],\r\n",
        "                   metadata=balloon_metadata, \r\n",
        "                   scale=1.5, \r\n",
        "                   instance_mode=ColorMode.SEGMENTATION   # remove the colors of unsegmented pixels\r\n",
        "    )\r\n",
        "    v = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\r\n",
        "    cv2_imshow(v.get_image()[:, :, ::-1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wsnChV7h8KOA"
      },
      "source": [
        "'''\r\n",
        "import torch\r\n",
        "score_list = []\r\n",
        "new_instances = []\r\n",
        "for d in random.sample(dataset_dicts, 5):    \r\n",
        "    im = cv2.imread(d[\"file_name\"])\r\n",
        "    outputs = predictor(im)\r\n",
        "    v = Visualizer(im[:, :, ::-1],\r\n",
        "                   metadata=balloon_metadata, \r\n",
        "                   scale=1.5, \r\n",
        "                   instance_mode=ColorMode.SEGMENTATION   # remove the colors of unsegmented pixels\r\n",
        "    )\r\n",
        "    for i in range(len(outputs[\"instances\"].scores)):\r\n",
        "      if(outputs[\"instances\"].scores[i] > 0.5):   \r\n",
        "        new_instances.append(outputs[\"instances\"][i])\r\n",
        "    \r\n",
        "    print(type(outputs[\"instances\"][0]))\r\n",
        "    print(new_instances[0])\r\n",
        "    #new_instances = torch.Tensor(new_instances)\r\n",
        "    #v = v.draw_instance_predictions(new_instances.to(\"cpu\"))\r\n",
        "    #cv2_imshow(v.get_image()[:, :, ::-1])\r\n",
        "    break\r\n",
        "'''    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0_sLBFj14KkR"
      },
      "source": [
        "'''\r\n",
        "d = dataset_dicts[0]\r\n",
        "im = cv2.imread(d[\"file_name\"])\r\n",
        "outputs = predictor(im)\r\n",
        "bboxes_pred = outputs[\"instances\"].scores\r\n",
        "print(bboxes_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Lqo41mP5rso"
      },
      "source": [
        "'''\r\n",
        "d = dataset_dicts[0]\r\n",
        "test = d[\"annotations\"]\r\n",
        "for i in range(len(test)):\r\n",
        "  bboxes_gt = test[i][\"bbox\"]\r\n",
        "  print(bboxes_gt)  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WiGWdrArxbaw"
      },
      "source": [
        "'''\r\n",
        "for d in dataset_dicts:\r\n",
        "  im = cv2.imread(d[\"file_name\"])\r\n",
        "  outputs = predictor(im)\r\n",
        "  #Test section for IOU\r\n",
        "  bboxes_gt = d[\"instances\"].bbox\r\n",
        "  bboxes_gt = structures.Boxes(torch.Tensor(bboxes_gt))\r\n",
        "  bboxes_pred = outputs[\"instances\"].pred_boxes\r\n",
        "  IOUs = structures.pairwise_iou(bboxes_gt, bboxes_pred)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BtXvaktkEO2m"
      },
      "source": [
        "for d in random.sample(dataset_dicts, 10):    \r\n",
        "    im = cv2.imread(d[\"file_name\"])\r\n",
        "    outputs = predictor(im)\r\n",
        "    v = Visualizer(im[:, :, ::-1],\r\n",
        "                   metadata=balloon_metadata, \r\n",
        "                   scale=1.5, \r\n",
        "                   instance_mode=ColorMode.SEGMENTATION   # remove the colors of unsegmented pixels\r\n",
        "    )\r\n",
        "    v = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\r\n",
        "    cv2_imshow(v.get_image()[:, :, ::-1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OZR_fEuPG-IY"
      },
      "source": [
        "#import the COCO Evaluator to use the COCO Metrics\r\n",
        "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\r\n",
        "from detectron2.data import build_detection_test_loader\r\n",
        "\r\n",
        "#Call the COCO Evaluator function and pass the Validation Dataset\r\n",
        "evaluator = COCOEvaluator(\"datset9\", cfg, False, output_dir=\"/output2/\")\r\n",
        "val_loader = build_detection_test_loader(cfg, \"datset9\")\r\n",
        "\r\n",
        "#Use the created predicted model in the previous step\r\n",
        "inference_on_dataset(predictor.model, val_loader, evaluator)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}